{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biological Signals Analysis - Week 4 Exercise\n",
    "\n",
    "### Created by Guy Singer | Jan. 31, 2024\n",
    "\n",
    "### Table of Contents:\n",
    "- Images as Arrays\n",
    "  - Python Example: Loading an Array Representation of a Microscopy Image\n",
    "- Color vs Grayscale Images\n",
    "- Thresholding\n",
    "  - Python Example: Thresholding with a Microscopy Image\n",
    "- Convolutions in Mathematics vs Image Processing\n",
    "  - Python Example: Smoothing a Microscopy Image by Convolving With a Gaussian Filter\n",
    "- Why Would We Want to Smooth an Image? - Edge Detection\n",
    "  - Python Example: Smoothing a Noisy Sigmoid Curve\n",
    "- Edge Detection: Sobel Kernel\n",
    "  - Python Example: Detecting Edges in a Microscopy Image With the Sobel Operator\n",
    "- Canny Edge Detection Algorithm\n",
    "  - Python Example: Detecting Canny Edges in a Microscopy Image With the Edge Detector\n",
    "- Hough Transforms for Shape Detection\n",
    "  - Python Example: Detecting Circles in a Microscopy Image With the Hough Transforms\n",
    "- Bonus Material: Deep Learning for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images as Arrays <a id=\"ims-as-arrays\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A digital image, in its simplest form, is a matrix of pixel values. Each pixel represents the smallest unit of an image, holding a value that corresponds to its intensity or color. In grayscale images, each pixel is usually represented by a single value, indicating various shades of gray. Color images typically use a combination of red, green, and blue (RGB) values for each pixel.\n",
    "\n",
    "Many Python libraries, such as `skimage` (Scikit-Image), provide an easy way to handle and process these images. Let's take a microscopy image as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "# Visualizing the image\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Displaying the array structure of the image\n",
    "print(\"Array Representation of the Image:\")\n",
    "print(image)\n",
    "print(\"\\nShape of the Image Array:\", image.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the image we see as an image is simply an array of values. For grayscale images these values will be between 0 and 255. For RGB images, there will be three dimensions of the array, each containing pixel values between 0 and 255.\n",
    "With this understanding of images, we can readily see that many of the operations we have already discussed in this course can be easily applied to images, with the goal of transforming them, filtering them, or augmenting them. Through such operations, we can extract useful information from our image data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color vs Grayscale Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images are often represented as two primary types: color and grayscale. To comprehend these representations in the context of images as arrays, we can break down the key differences and their significance.\n",
    "\n",
    "**Color Images:**\n",
    "- **Representation**: In color images, each pixel is represented as a combination of three primary colors: Red, Green, and Blue (RGB). Each color channel (R, G, B) is usually an 8-bit value ranging from 0 to 255, representing the intensity of that color.\n",
    "- **Array Structure**: Color images are represented as three separate 2D arrays, one for each color channel. These arrays are typically stacked together to form a 3D array.\n",
    "- **Data Shape**: A color image with dimensions (height, width) is represented as (height, width, 3), where the last dimension corresponds to the three color channels (R, G, B).\n",
    "\n",
    "**Grayscale Images:**\n",
    "- **Representation**: Grayscale images, on the other hand, contain only shades of gray, with pixel values ranging from 0 (black) to 255 (white). There is only one color channel in grayscale images.\n",
    "- **Array Structure**: Grayscale images are represented as a single 2D array, where each pixel's value directly represents its intensity or brightness.\n",
    "- **Data Shape**: A grayscale image with dimensions (height, width) is represented as (height, width), containing pixel values that represent the gray levels.\n",
    "\n",
    "**Significance in Image Processing:**\n",
    "- **Color Images**: Color images capture rich visual information with detailed color variations. They are suitable for tasks like object recognition, where color is an important distinguishing factor.\n",
    "- **Grayscale Images**: Grayscale images simplify the representation to intensity values, making them valuable for tasks where color information is less critical, such as edge detection, image thresholding, or processing in environments with limited resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = '2017brainbow844.jpg'\n",
    "\n",
    "# Load the image using PIL (Python Imaging Library)\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Display the original color image\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.title('Color Image')\n",
    "plt.axis('off')\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "grayscale_img = img.convert('L')\n",
    "\n",
    "# Display the grayscale version of the image\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(grayscale_img, cmap='gray')\n",
    "plt.title('Grayscale Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_path = '2017brainbow844.jpg'\n",
    "img = Image.open(image_path)\n",
    "\n",
    "# Convert the color image to grayscale\n",
    "grayscale_img = img.convert('L')\n",
    "\n",
    "# Convert the images to NumPy arrays\n",
    "color_array = np.array(img)\n",
    "grayscale_array = np.array(grayscale_img)\n",
    "\n",
    "# Create subplots for histograms\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Plot histogram for color image\n",
    "axs[0].hist(color_array.ravel(), bins=256, color='r', alpha=0.5, label='Color Image')\n",
    "axs[0].set_title('Histogram: Color Image')\n",
    "axs[0].set_xlabel('Pixel Value')\n",
    "axs[0].set_ylabel('Frequency')\n",
    "axs[0].legend()\n",
    "\n",
    "# Plot histogram for grayscale image\n",
    "axs[1].hist(grayscale_array.ravel(), bins=256, color='b', alpha=0.5, label='Grayscale Image')\n",
    "axs[1].set_title('Histogram: Grayscale Image')\n",
    "axs[1].set_xlabel('Pixel Value')\n",
    "axs[1].set_ylabel('Frequency')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question for class: why are there so many fewer values in the histogram of the grayscale image?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thresholding is a simple yet effective technique used in image processing to separate objects from the background. This technique is particularly useful in the field of microscopy image analysis, where distinguishing features of interest from the background is a common task.\n",
    "\n",
    "- **Binary Classification**: Thresholding classifies the pixel values in an image into two groups (foreground and background) based on a threshold value.\n",
    "- **Threshold Value**: A pixel value is compared against this threshold. If the pixel value is higher than the threshold, it is assigned one value (often white), otherwise, it is assigned another value (often black).\n",
    "\n",
    "\n",
    "In microscopy images, thresholding can help in identifying and segmenting specific cells or structures. It is a key step in preprocessing before performing more complex analyses, like object detection or image segmentation.\n",
    "\n",
    "### Types of Thresholding\n",
    "\n",
    "1. **Simple Thresholding**: Here, a global value is chosen manually. Pixels above this value are set to the maximum value, and others to the minimum.\n",
    "2. **Adaptive Thresholding**: This method calculates the threshold for smaller regions, allowing for varying lighting conditions across different areas of the image.\n",
    "3. **Otsu's Thresholding**: An automatic thresholding technique that chooses the optimal threshold value from the image histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python Example: Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "import numpy as np\n",
    "\n",
    "# Load the microscopy image\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "# Check if the image is already in grayscale\n",
    "if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "    # Convert to grayscale if it is a color image\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    # Use the image as is if it is already in grayscale\n",
    "    gray_image = image\n",
    "\n",
    "# Convert to 8-bit (if not already)\n",
    "if gray_image.dtype != np.uint8:\n",
    "    gray_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "# Simple Thresholding\n",
    "_, simple_thresh = cv2.threshold(gray_image, 128, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Adaptive Thresholding\n",
    "adaptive_thresh = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "                                        cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "# Otsu's Thresholding\n",
    "_, otsu_thresh = cv2.threshold(gray_image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(simple_thresh, cmap='gray')\n",
    "plt.title('Simple Thresholding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(adaptive_thresh, cmap='gray')\n",
    "plt.title('Adaptive Thresholding')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(otsu_thresh, cmap='gray')\n",
    "plt.title(\"Otsu's Thresholding\")\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution in Mathematics vs Image Processing <a id=\"convolutions-on-images\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Convolution\n",
    "\n",
    "As we discussed last week, in mathematics, convolution is an operation that combines two functions into a third function. It represents the amount of overlap of one function as it is shifted over another.\n",
    "\n",
    "For two continuous functions $ f $ and $ g $, convolution is defined as:\n",
    "\n",
    "$ (f * g)(t) = \\int_{-\\infty}^{\\infty} f(\\tau)g(t - \\tau) d\\tau $\n",
    "\n",
    "In the discrete case, typically used in digital signal processing, the formula becomes:\n",
    "\n",
    "$ (f * g)[n] = \\sum_{m=-\\infty}^{\\infty} f[m]g[n - m] $\n",
    "\n",
    "Mathematical convolution is commutative, associative, and distributive over addition. This means the order of the functions does not change the result, allowing for flexible application in various contexts.\n",
    "\n",
    "### Convolution in Image Processing\n",
    "\n",
    "In image processing, convolution is a critical technique used for applying filters to images, such as for blurring, sharpening, or edge detection.\n",
    "Convolution in image processing involves sliding a kernel (or filter) over the image, and performing pixel-wise multiplication and summing the results. Unlike mathematical convolution, the kernel is typically not reversed.\n",
    "\n",
    "The adapted convolution formula for image processing is:\n",
    "\n",
    "$ C(i, j) = \\sum_{u=-k}^{k} \\sum_{v=-k}^{k} I(i+u, j+v) \\cdot K(u, v) $\n",
    "\n",
    "Here, $ I $ represents the image, $ K $ is the kernel, and $ C $ is the convolved image.\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "- **Kernel Flipping**: Unlike mathematical convolution, the kernel in image processing is not flipped before application.\n",
    "- **Boundary Handling**: Image processing convolution must address boundary conditions, often through strategies like padding.\n",
    "- **Purpose and Application**: While mathematical convolution is more abstract, convolution in image processing is applied for practical image manipulations, such as filtering and feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Convolving Images With a Gaussian Filter <a id=\"convolved-filters\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Filter\n",
    "A Gaussian filter is a widely used filter in image processing, known for its properties in reducing image noise and smoothing details.\n",
    "The Gaussian filter is based on the Gaussian (normal) distribution. In a 2D Gaussian filter, the kernel values are calculated using the Gaussian function:\n",
    "\n",
    "$ G(x, y) = \\frac{1}{2 \\pi \\sigma^2} e^{- \\frac{x^2 + y^2}{2 \\sigma^2}} $\n",
    "\n",
    "where `x` and `y` are distances from the origin in the horizontal and vertical axes, and `σ` is the standard deviation of the Gaussian distribution. The values of the Gaussian filter add up to 1, ensuring that the overall brightness of the image remains constant after filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "def gaussian_kernel(size, sigma=1.0):\n",
    "    x, y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "    g = np.exp(-((x**2 + y**2) / (2.0 * sigma**2)))\n",
    "    return g / g.sum()\n",
    "\n",
    "size = 50  # Size of the kernel\n",
    "sigma = 5  # Standard deviation of the Gaussian\n",
    "kernel = gaussian_kernel(size, sigma)\n",
    "\n",
    "fig = plt.figure(figsize=(8, 6))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "X, Y = np.mgrid[-size//2 + 1:size//2 + 1, -size//2 + 1:size//2 + 1]\n",
    "Z = gaussian_kernel(size, sigma)\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='viridis', edgecolor='none')\n",
    "ax.set_title('3D Visualization of a Gaussian Kernel')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolution with a Gaussian smoothens an image by reducing its noise and details, which is essential in various applications, from enhancing image quality to preparing images for further analysis, like feature extraction. The Gaussian filter's effectiveness in image processing stems from its smooth bell-shaped curve, which provides natural weight distribution.\n",
    "\n",
    "The convolution of an image $ I $ with a Gaussian filter $ G $ is mathematically represented as:\n",
    "\n",
    "$ (I * G)(i, j) = \\sum_{u=-k}^{k} \\sum_{v=-k}^{k} I(i+u, j+v) \\cdot G(u, v) $\n",
    "\n",
    "In this formula:\n",
    "- $ (I * G)(i, j) $ denotes the value of the convolved image at position $ (i, j) $.\n",
    "- The sums iterate over the kernel's dimensions, with $ u $ and $ v $ spanning the width and height of the kernel, centered at $ (i, j) $.\n",
    "- $ I(i+u, j+v) $ is the original image's pixel value at position $ (i+u, j+v) $.\n",
    "- $ G(u, v) $ refers to the Gaussian filter's value at position $ (u, v) $.\n",
    "\n",
    "Through this operation, each pixel in the image is averaged with its neighbors, weighted according to the Gaussian filter. This results in a blurred version of the original image, with the extent of blurring being controlled by the standard deviation $ \\sigma $ of the Gaussian filter. A higher $ \\sigma $ means more blurring, as the filter has a broader curve and therefore encompasses more neighboring pixels in its calculations. Thus, convolution with a Gaussian filter reduces high-frequency components (like noise and edges).\n",
    "\n",
    "\n",
    "We'll apply a Gaussian filter to a microscopy image to observe this smoothing effect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "def update_plot(sigma):\n",
    "    filtered_image = gaussian_filter(image, sigma=sigma)\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "    ax[0].imshow(image, cmap='gray')\n",
    "    ax[0].set_title('Original Image')\n",
    "    ax[0].axis('off')\n",
    "    ax[1].imshow(filtered_image, cmap='gray')\n",
    "    ax[1].set_title(f'Filtered Image with Gaussian Filter (sigma={sigma})')\n",
    "    ax[1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sigma_slider = FloatSlider(\n",
    "    value=2.0,\n",
    "    min=0.0,\n",
    "    max=50.0,\n",
    "    step=0.1,\n",
    "    description='Sigma:',\n",
    "    continuous_update=False\n",
    ")\n",
    "interact(update_plot, sigma=sigma_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "sigma = 20  # Standard deviation for Gaussian kernel\n",
    "filtered_image = gaussian_filter(image, sigma=sigma)\n",
    "\n",
    "print(\"Array Representation of the Filtered Image:\")\n",
    "print(filtered_image)\n",
    "\n",
    "print(\"\\nArray Representation of the unfiltered Image:\")\n",
    "print(image)\n",
    "\n",
    "# Plotting histograms of the original and filtered image\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(image.ravel(), bins=256, color='blue', alpha=0.5, label='Original Image')\n",
    "plt.hist(filtered_image.ravel(), bins=256, color='red', alpha=0.5, label='Filtered Image')\n",
    "plt.title('Histogram of Pixel Intensities')\n",
    "plt.xlabel('Pixel Intensity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Would We Want to Smooth Out an Image? - Edge Detection <a id=\"smoothing-for-edge\" ></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge detection is a critical operation in image processing and computer vision, essential for feature extraction and object segmentation. At its core, edge detection is about detecting sharp changes in pixel intensity, which typically signify boundaries or transitions in an image.\n",
    "\n",
    "Mathematically, edges correspond to regions of high intensity change. This change can be identified using the concept of derivatives, similar to how we find the rate of change in calculus. In the context of digital images, we use the partial derivative to measure the change in intensity along the horizontal and vertical axes.\n",
    "\n",
    "For a two-dimensional image $ I(x, y) $, the gradient $ \\nabla I $ is a vector of the partial derivatives in the x and y directions:\n",
    "\n",
    "$ \\nabla I(x, y) = \\left( \\frac{\\partial I}{\\partial x}, \\frac{\\partial I}{\\partial y} \\right) $\n",
    "\n",
    "The magnitude of this gradient vector gives the rate of change of intensity at each point in the image:\n",
    "\n",
    "$ \\|\\nabla I(x, y)\\| = \\sqrt{\\left( \\frac{\\partial I}{\\partial x} \\right)^2 + \\left( \\frac{\\partial I}{\\partial y} \\right)^2} $\n",
    "\n",
    "High values of this magnitude indicate potential edges.\n",
    "\n",
    "### Noise & Edge Detection\n",
    "\n",
    "However, real-world images often contain noise – random variations in pixel intensity. Noise can significantly interfere with edge detection, as the derivatives amplify these variations, leading to false edges (see python example below)\n",
    "\n",
    "### Role of Smoothing Filters\n",
    "\n",
    "To mitigate the impact of noise, it is common practice to first smooth the image using a filter, such as the Gaussian filter we discussed, before applying edge detection. After smoothing, the partial derivatives are computed on the smoothed image $ I_{smoothed} $ instead of the original. This approach allows for a more accurate detection of true edges by minimizing the influence of noise.\n",
    "\n",
    "The result can be demonstrated in the python-generated plots below, where a sigmoid function representing an edge in an image is smoothed, leading to an obvious edge detection when taking its partial derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Creating a sharper sigmoid curve to represent a shift in pixel intensity values\n",
    "x = np.linspace(-10, 10, 400)\n",
    "sharp_sigmoid_curve = 1 / (1 + np.exp(-3*x))  # Steeper transition in the sigmoid\n",
    "noise = np.random.normal(0, 0.05, sharp_sigmoid_curve.shape)\n",
    "noisy_sigmoid_curve = sharp_sigmoid_curve + noise\n",
    "\n",
    "# Gaussian filter for more intense smoothing (h)\n",
    "sigma = 3  # Higher sigma for more intense smoothing\n",
    "smoothed_curve = gaussian_filter(noisy_sigmoid_curve, sigma=sigma)\n",
    "\n",
    "# Partial derivative of the smoothed and unsmoothed curves\n",
    "derivative_smoothed = np.gradient(smoothed_curve)\n",
    "derivative_unsmoothed = np.gradient(noisy_sigmoid_curve)\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(4, 1, figsize=(10, 8))\n",
    "\n",
    "axs[0].plot(x, noisy_sigmoid_curve, label=\"f(x) - Noisy Sigmoid Curve\")\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].plot(x, smoothed_curve, label=\"h * f - Smoothed Curve\")\n",
    "axs[1].legend()\n",
    "\n",
    "axs[2].plot(x, derivative_unsmoothed, label=\"Partial Derivative of f(x)\")\n",
    "axs[2].legend()\n",
    "\n",
    "axs[3].plot(x, derivative_smoothed, label=\"Partial Derivative of (h*f)\")\n",
    "axs[3].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobel Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sobel Kernel, or Sobel Operator, is a fundamental tool in image processing used primarily for edge detection. It is named after Irwin Sobel, who, along with Gary Feldman, introduced the concept in 1968. The Sobel Kernel is particularly effective in emphasizing edges and transitions in intensity in an image.\n",
    "\n",
    "### Concept of the Sobel Kernel\n",
    "\n",
    "The Sobel Kernel is a discrete differentiation operator. It computes an approximation of the gradient of the image intensity function. By applying the Sobel Kernel to an image, one can extract important information about the spatial variation of intensity, revealing the edges and structural features in the image.\n",
    "\n",
    "### How the Sobel Kernel Works\n",
    "\n",
    "The Sobel Kernel operates by convolving the kernel with the image, a process akin to a weighted averaging. There are two Sobel Kernels: one for detecting changes in horizontal gradients (Sobel X) and another for detecting changes in vertical gradients (Sobel Y).\n",
    "\n",
    "#### Sobel X Kernel (Detects Horizontal Edges):\n",
    "\n",
    "$ G_x = \\begin{bmatrix} -1 & 0 & +1 \\\\ -2 & 0 & +2 \\\\ -1 & 0 & +1 \\end{bmatrix} $\n",
    "\n",
    "#### Sobel Y Kernel (Detects Vertical Edges):\n",
    "\n",
    "$ G_y = \\begin{bmatrix} -1 & -2 & -1 \\\\ 0 & 0 & 0 \\\\ +1 & +2 & +1 \\end{bmatrix} $\n",
    "\n",
    "- **Gx**: The horizontal edge kernel emphasizes horizontal edges by detecting changes in brightness along the x-axis.\n",
    "- **Gy**: The vertical edge kernel emphasizes vertical edges by detecting changes in brightness along the y-axis.\n",
    "\n",
    "### Application of the Sobel Operator\n",
    "\n",
    "When the kernels are applied to an image, they produce two derivative estimates: one for horizontal changes (Gx) and one for vertical changes (Gy). These derivatives can be combined to find the overall gradient magnitude at each point in the image:\n",
    "\n",
    "$ Gradient\\;Magnitude = \\sqrt{Gx^2 + Gy^2} $\n",
    "\n",
    "The direction of the gradient can also be calculated, which indicates the direction of the sharpest intensity change:\n",
    "\n",
    "$ Gradient\\;Direction = \\arctan2(Gy, Gx) $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "\n",
    "# Load the microscopy image\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "# Check if the image is already in grayscale\n",
    "if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "    # Convert the image to grayscale\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    gray_image = image\n",
    "\n",
    "# Apply Sobel kernels\n",
    "sobel_x = cv2.Sobel(gray_image, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobel_y = cv2.Sobel(gray_image, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "# Calculate the gradient magnitude\n",
    "gradient_magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "\n",
    "# Display the results\n",
    "fig, axs = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "axs[0].imshow(gray_image, cmap='gray')\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(np.abs(sobel_x), cmap='gray')\n",
    "axs[1].set_title('Sobel X')\n",
    "axs[1].axis('off')\n",
    "\n",
    "axs[2].imshow(np.abs(sobel_y), cmap='gray')\n",
    "axs[2].set_title('Sobel Y')\n",
    "axs[2].axis('off')\n",
    "\n",
    "axs[3].imshow(gradient_magnitude, cmap='gray')\n",
    "axs[3].set_title('Gradient Magnitude')\n",
    "axs[3].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canny Edge Detection Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Canny Edge Detection algorithm, developed by John F. Canny in 1986, is a multi-stage process to detect a wide range of edges in images. It aims to satisfy three main criteria:\n",
    "1. **Good Detection**: The algorithm should mark as many real edges in the image as possible.\n",
    "2. **Good Localization**: Edges marked should be as close as possible to the edge in the real image.\n",
    "3. **Minimal Response**: Each edge should only be marked once, and where possible, image noise should not create false edges.\n",
    "\n",
    "### Stages of the Canny Edge Detection Algorithm\n",
    "\n",
    "#### 1. Noise Reduction\n",
    "Since edge detection is susceptible to noise in the image, the first step is to reduce the noise. This is typically done using a Gaussian filter. The filter smooths the image to reduce the impact of obvious noise on the edge detection.\n",
    "\n",
    "#### 2. Finding the Intensity Gradient of the Image\n",
    "The smoothed image is then filtered with a Sobel kernel in both horizontal and vertical directions to get the first derivative in the horizontal direction (Gx) and the vertical direction (Gy). From these, the edge gradient and direction can be determined:\n",
    "\n",
    "$ Gradient\\;Magnitude = \\sqrt{Gx^2 + Gy^2} $\n",
    "\n",
    "$ Angle = \\arctan2(Gy, Gx) $\n",
    "\n",
    "The gradient direction is rounded to one of four angles representing vertical, horizontal, and two diagonal directions.\n",
    "\n",
    "#### 3. Non-maximum Suppression\n",
    "To get rid of spurious response to edge detection, the edges should be thinned. In this step, pixels that are not part of the edge are suppressed. Pixel values are set to 0 if they are not the maximum among their neighbors in the direction of the edge gradient.\n",
    "\n",
    "#### 4. Double Threshold\n",
    "After applying non-maximum suppression, it's possible to have weak and strong edges. To distinguish between them, two thresholds are set: a high and a low threshold. Strong edges are defined as intensity gradients higher than the high threshold, and weak edges are those higher than the low threshold but smaller than the high threshold. Weak edges that are connected to strong edges are considered part of the edge, otherwise, they are suppressed.\n",
    "\n",
    "#### 5. Edge Tracking by Hysteresis\n",
    "The final step involves converting weak edges into strong ones if they are connected to strong edges. This process is known as hysteresis. It helps to ensure that weak edges resulting from true edges are kept while others are discarded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "\n",
    "# Load the microscopy image\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "image = skimage.io.imread(image_url)\n",
    "\n",
    "# Convert to grayscale if the image is in color\n",
    "if len(image.shape) > 2 and image.shape[2] == 3:\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    gray_image = image\n",
    "\n",
    "# Convert to 8-bit (if not already)\n",
    "if gray_image.dtype != np.uint8:\n",
    "    # Scale to the range 0-255 if necessary\n",
    "    gray_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray_image, 100, 200)  # Threshold values can be adjusted\n",
    "\n",
    "# Display the results\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "axs[0].imshow(gray_image, cmap='gray')\n",
    "axs[0].set_title('Original Image')\n",
    "axs[0].axis('off')\n",
    "\n",
    "axs[1].imshow(edges, cmap='gray')\n",
    "axs[1].set_title('Canny Edge Detection')\n",
    "axs[1].axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hough Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hough Transforms are a powerful technique for detecting simple shapes like lines, circles, and other parametric forms in images. This method is particularly useful in situations where these shapes are distorted or obscured. Hough Transforms convert the problem of detecting shapes in an image into a voting procedure within a mathematical space, known as the Hough space. This technique is beneficial when dealing with imperfect shape instances, which are often encountered in biological images due to noise or partial occlusion.\n",
    "\n",
    "### The Shift from Image Space to Parameter Space\n",
    "\n",
    "The fundamental concept of the Hough Transform involves a shift in perspective:\n",
    "\n",
    "- **Image Space**: Where our image exists, and each pixel has coordinates like (x, y).\n",
    "- **Parameter Space (Hough Space)**: A conceptual mathematical space where each point or shape in the image space is represented by its defining parameters.\n",
    "\n",
    "The idea is to explore the relationships between these spaces to detect shapes.\n",
    "\n",
    "### Hough Transforms for Line Detection\n",
    "\n",
    "One of the simplest applications of the Hough Transform is detecting straight lines, which is often represented as a problem of identifying points that lie along the same line.\n",
    "\n",
    "In mathematical terms, a line can be represented as $ y = mx + c $. However, this formulation is not suitable for vertical lines as the slope (m) becomes infinite. Therefore, we use a polar coordinate representation:\n",
    "\n",
    "$ \\rho = x \\cos \\theta + y \\sin \\theta $\n",
    "\n",
    "Here, $ \\rho $ is the perpendicular distance from the origin to the line, and $ \\theta $ is the angle formed by the line perpendicular to the x-axis.\n",
    "\n",
    "#### The Voting Process in Hough Space\n",
    "\n",
    "In the Hough space, a single point in the image space maps to a sinusoidal curve representing all possible lines passing through it. When multiple curves intersect in the Hough space, it signifies that the corresponding points in the image space are aligned, indicating a line's presence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# Create a simple image with a line\n",
    "image = np.zeros((100, 100), dtype=np.uint8)\n",
    "image[50, 20:80] = 255  # Creating a horizontal line\n",
    "\n",
    "# Apply Hough Transform\n",
    "edges = cv2.Canny(image, 50, 150)\n",
    "lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=20)\n",
    "\n",
    "# Visualize the original image and its Hough Transform\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Original Image\n",
    "ax[0].imshow(image, cmap='gray')\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].axis('off')\n",
    "\n",
    "# Hough Space\n",
    "if lines is not None:\n",
    "    for rho, theta in lines[:, 0]:\n",
    "        a = np.cos(theta)\n",
    "        b = np.sin(theta)\n",
    "        x0 = a * rho\n",
    "        y0 = b * rho\n",
    "        x1 = int(x0 + 1000 * (-b))\n",
    "        y1 = int(y0 + 1000 * (a))\n",
    "        x2 = int(x0 - 1000 * (-b))\n",
    "        y2 = int(y0 - 1000 * (a))\n",
    "        ax[1].plot((x1, x2), (y1, y2), 'red')\n",
    "ax[1].set_xlim([0, 180])\n",
    "ax[1].set_ylim([0, max(image.shape)])\n",
    "ax[1].set_xlabel('Theta')\n",
    "ax[1].set_ylabel('Rho')\n",
    "ax[1].set_title('Hough Space')\n",
    "ax[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation:\n",
    "\n",
    "- **Image Creation**: A simple binary image with a horizontal line is created.\n",
    "- **Edge Detection**: The Canny edge detector is applied to find edges in the image, which is a common preprocessing step before applying the Hough Transform.\n",
    "- **Hough Transform**: `cv2.HoughLines` is used to apply the Hough Transform. It returns an array of `rho` and `theta` values representing the detected lines.\n",
    "- **Visualization**:\n",
    "   - The original image is displayed to show the line in the image space.\n",
    "   - The Hough Space is visualized by plotting the lines represented by the detected `rho` and `theta` values. Each line in the Hough space corresponds to a curve for a point on the actual line in the image space. The intersection of these lines in Hough space represents the detected line in the image space.\n",
    "\n",
    "This code provides a visual demonstration of how the Hough Transform can be used to detect lines in an image, and how the intersection of curves in Hough space corresponds to these lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define two points in image space\n",
    "point1 = (4, 2)  # (x1, y1)\n",
    "point2 = (2, 5)  # (x2, y2)\n",
    "\n",
    "# Generate theta values\n",
    "theta = np.linspace(-np.pi, np.pi, 400)\n",
    "\n",
    "# Hough Transform equations for the two points\n",
    "rho1 = point1[0] * np.cos(theta) + point1[1] * np.sin(theta)\n",
    "rho2 = point2[0] * np.cos(theta) + point2[1] * np.sin(theta)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(theta, rho1, label=f'Point 1: {point1}')\n",
    "plt.plot(theta, rho2, label=f'Point 2: {point2}')\n",
    "plt.xlabel('Theta (radians)')\n",
    "plt.ylabel('Rho')\n",
    "plt.title('Mapping Points to Hough Space')\n",
    "plt.axhline(y=0, color='black',linewidth=0.5)\n",
    "plt.axvline(x=0, color='black',linewidth=0.5)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hough Transforms for Circle Detection\n",
    "\n",
    "For detecting circles, a similar principle is applied. A circle with radius $ r $ and center $(a, b)$ in the image space can be described by:\n",
    "\n",
    "$ (x - a)^2 + (y - b)^2 = r^2 $\n",
    "\n",
    "In Hough space, this translates to a more complex parameter space where intersections indicate the presence of a circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io\n",
    "\n",
    "# Load the microscopy image\n",
    "image_url = 'https://cildata.crbs.ucsd.edu/media/images/13901/13901.tif'\n",
    "original_image = skimage.io.imread(image_url)\n",
    "\n",
    "image_for_drawing = original_image.copy()\n",
    "\n",
    "if len(original_image.shape) > 2 and original_image.shape[2] == 3:\n",
    "    gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n",
    "else:\n",
    "    gray_image = original_image\n",
    "if gray_image.dtype != np.uint8:\n",
    "    gray_image = cv2.normalize(gray_image, None, 0, 255, cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n",
    "\n",
    "# Apply Canny edge detection\n",
    "edges = cv2.Canny(gray_image, 100, 200)\n",
    "\n",
    "# Apply Hough Circle Transform on the edges with adjusted radius parameters\n",
    "circles = cv2.HoughCircles(edges, cv2.HOUGH_GRADIENT, dp=1.2, minDist=20, param1=50, param2=30, minRadius=0, maxRadius=100)\n",
    "\n",
    "# Draw the detected circles on the copy of the original image\n",
    "if circles is not None:\n",
    "    circles = np.uint16(np.around(circles))\n",
    "    for i in circles[0, :]:\n",
    "        center = (i[0], i[1])  # Circle center\n",
    "        radius = i[2]  # Circle radius\n",
    "        # Draw the circle outline in red\n",
    "        cv2.circle(image_for_drawing, center, radius, (0, 0, 255), 2)\n",
    "        # Draw the center of the circle in red\n",
    "        cv2.circle(image_for_drawing, center, 2, (0, 0, 255), 3)\n",
    "\n",
    "# Display the results\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(image_for_drawing, cmap='gray')\n",
    "plt.title('Circles Detected with Hough Transform on Canny Edges')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Material: Deep Learning for Object Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Artificial Neural Networks (ANNs) are a foundational concept in the field of machine learning and artificial intelligence, inspired by the biological neural networks that constitute animal brains. The concept of ANNs is inspired by biological neurons in the brain. Each biological neuron receives inputs through its dendrites (analogous to the inputs in an ANN), processes the signals, and then transmits the output to other neurons via its axon and synapses.\n",
    "An ANN is composed of layers of interconnected nodes or 'neurons,' each of which performs a simple computation. The basic structure includes an input layer, one or more hidden layers, and an output layer.\n",
    "\n",
    "- **Neurons**: Each neuron receives input from either the data (in the case of the input layer) or the output of neurons from the previous layer. \n",
    "- **Connections**: Every connection between two neurons has a weight associated with it. These weights determine the importance of the input values.\n",
    "\n",
    "The output of a neuron is a function of the weighted sum of its inputs, plus a bias term. This can be mathematically represented as:\n",
    "\n",
    "$ y = f(\\sum (w_i \\cdot x_i) + b) $\n",
    "\n",
    "Where:\n",
    "- $ y $ is the output.\n",
    "- $ w_i $ represents the weight of the ith connection.\n",
    "- $ x_i $ is the ith input to the neuron.\n",
    "- $ b $ is the bias term.\n",
    "- $ f $ is an activation function that introduces non-linearity.\n",
    "\n",
    "In the context of image classification:\n",
    "- The **number of neurons in the output layer** corresponds to the **number of classes**. For instance, in a task to classify images as either cats or dogs, the output layer would consist of two neurons.\n",
    "- Each neuron in the output layer represents a class, and the output value signifies the likelihood or probability of the input belonging to that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Create a simple CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1), name='Conv2D_1'),\n",
    "    MaxPooling2D(pool_size=(2, 2), name='MaxPooling2D_1'),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu', name='Conv2D_2'),\n",
    "    MaxPooling2D(pool_size=(2, 2), name='MaxPooling2D_2'),\n",
    "    Flatten(name='Flatten'),\n",
    "    Dense(128, activation='relu', name='Dense_1'),\n",
    "    Dense(10, activation='softmax', name='Output')\n",
    "])\n",
    "\n",
    "# Visualize the model\n",
    "visualkeras.layered_view(model, legend=True, to_file='cnn_visualization.png')  # Save as PNG\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Functions\n",
    "Functions applied to the output of a neural network layer, introducing non-linearity into the model.\n",
    "\n",
    "- **Linear Limitation**: A neural network without activation functions would essentially be a linear regression model, capable only of understanding linear mappings between inputs and outputs. This is inadequate for complex tasks like image recognition or natural language processing.\n",
    "- **Non-linear Mapping**: Activation functions provide the necessary non-linearity, allowing neural networks to learn and represent more complex relationships in data.\n",
    "\n",
    "### Biological Analogy\n",
    "\n",
    "- In biological neural networks, synapses can act like thresholding mechanisms, determining whether or not to activate a neuron in response to the received signals. Activation functions in artificial neural networks similarly decide how much signal to pass forward.\n",
    "\n",
    "\n",
    "1. **Sigmoid Function**: Often used in binary classification, the sigmoid function maps input values to the range between 0 and 1, making it useful for probabilities. However, it's less popular now due to issues like vanishing gradients.\n",
    "\n",
    "2. **ReLU (Rectified Linear Unit)**: This function outputs the input directly if positive; otherwise, it outputs zero. It's widely used because of its simplicity and efficiency, especially in deep neural networks.\n",
    "\n",
    "3. **TanH (Hyperbolic Tangent)**: Similar to the sigmoid but maps values between -1 and 1. It's often used in hidden layers of neural networks.\n",
    "\n",
    "4. **Leaky ReLU**: A variation of ReLU, it allows a small gradient when the unit is not active, overcoming some of the limitations of the original ReLU function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Activation functions\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def leaky_relu(x, alpha=0.01):\n",
    "    return np.where(x > 0, x, x * alpha)\n",
    "\n",
    "# Generate a range of values\n",
    "x = np.linspace(-10, 10, 100)\n",
    "\n",
    "# Create plots\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Sigmoid Function Plot\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(x, sigmoid(x), label=\"Sigmoid\")\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"σ(x)\")\n",
    "plt.text(4, 0.8, r'$\\sigma(x) = \\frac{1}{1+e^{-x}}$', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# ReLU Function Plot\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(x, relu(x), label=\"ReLU\")\n",
    "plt.title(\"ReLU Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"ReLU(x)\")\n",
    "plt.text(4, 8, r'$ReLU(x) = max(0, x)$', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# TanH Function Plot\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(x, tanh(x), label=\"TanH\")\n",
    "plt.title(\"TanH Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"tanh(x)\")\n",
    "plt.text(4, 0.6, r'$tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "# Leaky ReLU Function Plot\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(x, leaky_relu(x), label=\"Leaky ReLU\")\n",
    "plt.title(\"Leaky ReLU Function\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Leaky ReLU(x)\")\n",
    "plt.text(4, -1, r'$LeakyReLU(x) = x \\text{ if } x > 0 \\text{ else } 0.01x$', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
